{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84a282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨çˆ¬å–é é¢: 35it [22:41, 38.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ ç¬¬ 36 é ç„¡èª²ç¨‹å…§å®¹ï¼Œçˆ¬èŸ²çµæŸã€‚\n",
      "\n",
      "âœ… çˆ¬å–å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜è‡³ï¼šcoursera_ChatGPT_TS.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 33\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "def get_extra_info(course_url):\n",
    "    start_time = \"\"\n",
    "    suggested_study_time = \"\"\n",
    "    study_duration = \"\"\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        start_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-za0201.cds-10.cds-11.cds-grid-item > div.cds-9.css-0.cds-11.cds-grid-item.cds-56 > div > div > div > div.cds-9.css-0.cds-11.cds-grid-item.cds-56.cds-79 > div.css-y6ppwi > div > div > div > form > button > span > div > div > span\"\n",
    "        )\n",
    "        suggested_study_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fk6qfz\"\n",
    "        )\n",
    "        study_duration_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fw9ih3\"\n",
    "        )\n",
    "        start_time = start_time_element.text.strip() if start_time_element else \"\"\n",
    "        suggested_study_time = (\n",
    "            suggested_study_time_element.text.strip()\n",
    "            if suggested_study_time_element\n",
    "            else \"\"\n",
    "        )\n",
    "        study_duration = (\n",
    "            study_duration_element.text.strip() if study_duration_element else \"\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ“·å–èª²ç¨‹é¡å¤–è³‡è¨Šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return start_time, suggested_study_time, study_duration\n",
    "\n",
    "\n",
    "def get_course_details(course_url):\n",
    "    details = {\n",
    "        \"èª²ç¨‹\": \"\",\n",
    "        \"æŠ€èƒ½\": \"\",\n",
    "        \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "        \"å¸«è³‡\": \"\",\n",
    "        \"é–‹èª²æ™‚é–“\": \"\",\n",
    "        \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "        \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        course_title = soup.find(\n",
    "            \"a\", class_=\"cds-119 cds-113 cds-115 css-17cxvu3 cds-142\", href=\"#modules\"\n",
    "        )\n",
    "        details[\"èª²ç¨‹\"] = course_title.text.strip() if course_title else \"\"\n",
    "        skills = []\n",
    "        skill_spans = soup.find_all(\"span\", {\"class\": \"css-1l1jvyr\"})\n",
    "        for span in skill_spans:\n",
    "            skill_link = span.find(\n",
    "                \"a\", {\"class\": \"cds-119 cds-113 cds-115 css-113xph7 cds-142\"}\n",
    "            )\n",
    "            if skill_link:\n",
    "                skills.append(skill_link.get_text(strip=True))\n",
    "        details[\"æŠ€èƒ½\"] = \", \".join(skills) if skills else \"\"\n",
    "        modules = []\n",
    "        for mod in soup.find_all(\"h3\", class_=\"cds-119 css-1pxm1ir cds-121\"):\n",
    "            modules.append(mod.text.strip())\n",
    "        details[\"èª²ç¨‹è³‡è¨Š\"] = \" | \".join(modules)\n",
    "        instructors = []\n",
    "        for span in soup.find_all(\"span\", class_=\"css-6ecy9b\"):\n",
    "            name = span.text.strip()\n",
    "            if (\n",
    "                name not in instructors\n",
    "                and len(name.split()) >= 2\n",
    "                and not any(\n",
    "                    keyword in name.lower()\n",
    "                    for keyword in [\n",
    "                        \"star\",\n",
    "                        \"more\",\n",
    "                        \"access\",\n",
    "                        \"certificate\",\n",
    "                        \"refund\",\n",
    "                        \"?\",\n",
    "                    ]\n",
    "                )\n",
    "            ):\n",
    "                instructors.append(name)\n",
    "        details[\"å¸«è³‡\"] = \", \".join(instructors)\n",
    "        start_time, suggested_study_time, study_duration = get_extra_info(course_url)\n",
    "        details[\"é–‹èª²æ™‚é–“\"] = start_time\n",
    "        details[\"å»ºè­°å­¸ç¿’æ™‚é–“\"] = suggested_study_time\n",
    "        details[\"å­¸ç¿’æ™‚é•·\"] = study_duration\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è©³æƒ…é é€£ç·šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return details\n",
    "\n",
    "\n",
    "page = 1\n",
    "pbar = tqdm(desc=\"æ­£åœ¨çˆ¬å–é é¢\", ncols=100)\n",
    "while True:\n",
    "    url = f\"https://www.coursera.org/courses?query=chatgpt&page={page}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\\nâš ï¸ ç¬¬ {page} é é€£ç·šå¤±æ•—ï¼š{e}\")\n",
    "        break\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    course_cards = soup.find_all(\"div\", class_=\"cds-ProductCard-content\")\n",
    "    if not course_cards:\n",
    "        print(f\"\\nðŸ“„ ç¬¬ {page} é ç„¡èª²ç¨‹å…§å®¹ï¼Œçˆ¬èŸ²çµæŸã€‚\")\n",
    "        break\n",
    "    for card in course_cards:\n",
    "        title_elem = card.find(\"h3\", class_=\"cds-CommonCard-title css-6ecy9b\")\n",
    "        title = title_elem.text.strip() if title_elem else \"N/A\"\n",
    "        rating_elem = card.find(\"div\", class_=\"css-1whdyhf\")\n",
    "        rating = (\n",
    "            rating_elem.text.strip().replace(\"Rating, \", \"\") if rating_elem else \"N/A\"\n",
    "        )\n",
    "        review = \"N/A\"\n",
    "        review_elems = card.find_all(\"div\", class_=\"css-vac8rf\")\n",
    "        for elem in review_elems:\n",
    "            if \"reviews\" in elem.text.lower():\n",
    "                review = elem.text.strip()\n",
    "                break\n",
    "        meta_elem = card.find(\"div\", class_=\"cds-CommonCard-metadata\")\n",
    "        meta = (\n",
    "            meta_elem.find(\"p\", class_=\"css-vac8rf\").text.strip()\n",
    "            if meta_elem and meta_elem.find(\"p\", class_=\"css-vac8rf\")\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        link_elem = card.find(\"a\", class_=\"cds-CommonCard-titleLink\")\n",
    "        if link_elem and link_elem.get(\"href\"):\n",
    "            course_url = \"https://www.coursera.org\" + link_elem.get(\"href\")\n",
    "        else:\n",
    "            course_url = \"\"\n",
    "        if course_url:\n",
    "            detail_data = get_course_details(course_url)\n",
    "        else:\n",
    "            detail_data = {\n",
    "                \"èª²ç¨‹\": \"\",\n",
    "                \"æŠ€èƒ½\": \"\",\n",
    "                \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "                \"å¸«è³‡\": \"\",\n",
    "                \"é–‹èª²æ™‚é–“\": \"\",\n",
    "                \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "                \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "            }\n",
    "        row = {\n",
    "            \"èª²ç¨‹åç¨±\": title,\n",
    "            \"è©•åˆ†\": rating,\n",
    "            \"è©•è«–æ•¸\": review,\n",
    "            \"Metadata\": meta,\n",
    "            \"èª²ç¨‹ç¶²å€\": course_url,\n",
    "            \"èª²ç¨‹\": detail_data[\"èª²ç¨‹\"],\n",
    "            \"æŠ€èƒ½\": detail_data[\"æŠ€èƒ½\"],\n",
    "            \"èª²ç¨‹è³‡è¨Š\": detail_data[\"èª²ç¨‹è³‡è¨Š\"],\n",
    "            \"å¸«è³‡\": detail_data[\"å¸«è³‡\"],\n",
    "            \"é–‹èª²æ™‚é–“\": detail_data[\"é–‹èª²æ™‚é–“\"],\n",
    "            \"å»ºè­°å­¸ç¿’æ™‚é–“\": detail_data[\"å»ºè­°å­¸ç¿’æ™‚é–“\"],\n",
    "            \"å­¸ç¿’æ™‚é•·\": detail_data[\"å­¸ç¿’æ™‚é•·\"],\n",
    "        }\n",
    "        all_data.append(row)\n",
    "    page += 1\n",
    "    pbar.update(1)\n",
    "    time.sleep(3)\n",
    "pbar.close()\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "output_file = \"coursera_ChatGPT_TS.csv\"\n",
    "try:\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… çˆ¬å–å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜è‡³ï¼š{output_file}\")\n",
    "except PermissionError:\n",
    "    print(f\"\\nâŒ ç„¡æ³•å¯«å…¥ '{output_file}'ï¼Œè«‹é—œé–‰æª”æ¡ˆæˆ–é¸æ“‡å…¶ä»–è·¯å¾‘ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 62\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "def get_extra_info(course_url):\n",
    "    start_time = \"\"\n",
    "    suggested_study_time = \"\"\n",
    "    study_duration = \"\"\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        start_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-za0201.cds-10.cds-11.cds-grid-item > div.cds-9.css-0.cds-11.cds-grid-item.cds-56 > div > div > div > div.cds-9.css-0.cds-11.cds-grid-item.cds-56.cds-79 > div.css-y6ppwi > div > div > div > form > button > span > div > div > span\"\n",
    "        )\n",
    "        suggested_study_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fk6qfz\"\n",
    "        )\n",
    "        study_duration_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fw9ih3\"\n",
    "        )\n",
    "        start_time = start_time_element.text.strip() if start_time_element else \"\"\n",
    "        suggested_study_time = (\n",
    "            suggested_study_time_element.text.strip()\n",
    "            if suggested_study_time_element\n",
    "            else \"\"\n",
    "        )\n",
    "        study_duration = (\n",
    "            study_duration_element.text.strip() if study_duration_element else \"\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ“·å–èª²ç¨‹é¡å¤–è³‡è¨Šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return start_time, suggested_study_time, study_duration\n",
    "\n",
    "\n",
    "def get_course_details(course_url):\n",
    "    details = {\n",
    "        \"èª²ç¨‹\": \"\",\n",
    "        \"æŠ€èƒ½\": \"\",\n",
    "        \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "        \"å¸«è³‡\": \"\",\n",
    "        \"é–‹èª²æ™‚é–“\": \"\",\n",
    "        \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "        \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        course_title = soup.find(\n",
    "            \"a\", class_=\"cds-119 cds-113 cds-115 css-17cxvu3 cds-142\", href=\"#modules\"\n",
    "        )\n",
    "        details[\"èª²ç¨‹\"] = course_title.text.strip() if course_title else \"\"\n",
    "        skills = []\n",
    "        skill_spans = soup.find_all(\"span\", {\"class\": \"css-1l1jvyr\"})\n",
    "        for span in skill_spans:\n",
    "            skill_link = span.find(\n",
    "                \"a\", {\"class\": \"cds-119 cds-113 cds-115 css-113xph7 cds-142\"}\n",
    "            )\n",
    "            if skill_link:\n",
    "                skills.append(skill_link.get_text(strip=True))\n",
    "        details[\"æŠ€èƒ½\"] = \", \".join(skills) if skills else \"\"\n",
    "        modules = []\n",
    "        for mod in soup.find_all(\"h3\", class_=\"cds-119 css-1pxm1ir cds-121\"):\n",
    "            modules.append(mod.text.strip())\n",
    "        details[\"èª²ç¨‹è³‡è¨Š\"] = \" | \".join(modules)\n",
    "        instructors = []\n",
    "        for span in soup.find_all(\"span\", class_=\"css-6ecy9b\"):\n",
    "            name = span.text.strip()\n",
    "            if (\n",
    "                name not in instructors\n",
    "                and len(name.split()) >= 2\n",
    "                and not any(\n",
    "                    keyword in name.lower()\n",
    "                    for keyword in [\n",
    "                        \"star\",\n",
    "                        \"more\",\n",
    "                        \"access\",\n",
    "                        \"certificate\",\n",
    "                        \"refund\",\n",
    "                        \"?\",\n",
    "                    ]\n",
    "                )\n",
    "            ):\n",
    "                instructors.append(name)\n",
    "        details[\"å¸«è³‡\"] = \", \".join(instructors)\n",
    "        start_time, suggested_study_time, study_duration = get_extra_info(course_url)\n",
    "        details[\"é–‹èª²æ™‚é–“\"] = start_time\n",
    "        details[\"å»ºè­°å­¸ç¿’æ™‚é–“\"] = suggested_study_time\n",
    "        details[\"å­¸ç¿’æ™‚é•·\"] = study_duration\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è©³æƒ…é é€£ç·šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return details\n",
    "\n",
    "\n",
    "page = 1\n",
    "pbar = tqdm(desc=\"æ­£åœ¨çˆ¬å–é é¢\", ncols=100)\n",
    "while True:\n",
    "    url = f\"https://www.coursera.org/courses?query=coding&page={page}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\\nâš ï¸ ç¬¬ {page} é é€£ç·šå¤±æ•—ï¼š{e}\")\n",
    "        break\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    course_cards = soup.find_all(\"div\", class_=\"cds-ProductCard-content\")\n",
    "    if not course_cards:\n",
    "        print(f\"\\nðŸ“„ ç¬¬ {page} é ç„¡èª²ç¨‹å…§å®¹ï¼Œçˆ¬èŸ²çµæŸã€‚\")\n",
    "        break\n",
    "    for card in course_cards:\n",
    "        title_elem = card.find(\"h3\", class_=\"cds-CommonCard-title css-6ecy9b\")\n",
    "        title = title_elem.text.strip() if title_elem else \"N/A\"\n",
    "        rating_elem = card.find(\"div\", class_=\"css-1whdyhf\")\n",
    "        rating = (\n",
    "            rating_elem.text.strip().replace(\"Rating, \", \"\") if rating_elem else \"N/A\"\n",
    "        )\n",
    "        review = \"N/A\"\n",
    "        review_elems = card.find_all(\"div\", class_=\"css-vac8rf\")\n",
    "        for elem in review_elems:\n",
    "            if \"reviews\" in elem.text.lower():\n",
    "                review = elem.text.strip()\n",
    "                break\n",
    "        meta_elem = card.find(\"div\", class_=\"cds-CommonCard-metadata\")\n",
    "        meta = (\n",
    "            meta_elem.find(\"p\", class_=\"css-vac8rf\").text.strip()\n",
    "            if meta_elem and meta_elem.find(\"p\", class_=\"css-vac8rf\")\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        link_elem = card.find(\"a\", class_=\"cds-CommonCard-titleLink\")\n",
    "        if link_elem and link_elem.get(\"href\"):\n",
    "            course_url = \"https://www.coursera.org\" + link_elem.get(\"href\")\n",
    "        else:\n",
    "            course_url = \"\"\n",
    "        if course_url:\n",
    "            detail_data = get_course_details(course_url)\n",
    "        else:\n",
    "            detail_data = {\n",
    "                \"èª²ç¨‹\": \"\",\n",
    "                \"æŠ€èƒ½\": \"\",\n",
    "                \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "                \"å¸«è³‡\": \"\",\n",
    "                \"é–‹èª²æ™‚é–“\": \"\",\n",
    "                \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "                \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "            }\n",
    "        row = {\n",
    "            \"èª²ç¨‹åç¨±\": title,\n",
    "            \"è©•åˆ†\": rating,\n",
    "            \"è©•è«–æ•¸\": review,\n",
    "            \"Metadata\": meta,\n",
    "            \"èª²ç¨‹ç¶²å€\": course_url,\n",
    "            \"èª²ç¨‹\": detail_data[\"èª²ç¨‹\"],\n",
    "            \"æŠ€èƒ½\": detail_data[\"æŠ€èƒ½\"],\n",
    "            \"èª²ç¨‹è³‡è¨Š\": detail_data[\"èª²ç¨‹è³‡è¨Š\"],\n",
    "            \"å¸«è³‡\": detail_data[\"å¸«è³‡\"],\n",
    "            \"é–‹èª²æ™‚é–“\": detail_data[\"é–‹èª²æ™‚é–“\"],\n",
    "            \"å»ºè­°å­¸ç¿’æ™‚é–“\": detail_data[\"å»ºè­°å­¸ç¿’æ™‚é–“\"],\n",
    "            \"å­¸ç¿’æ™‚é•·\": detail_data[\"å­¸ç¿’æ™‚é•·\"],\n",
    "        }\n",
    "        all_data.append(row)\n",
    "    page += 1\n",
    "    pbar.update(1)\n",
    "    time.sleep(3)\n",
    "pbar.close()\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "output_file = \"coursera_coding_TS.csv\"\n",
    "try:\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… çˆ¬å–å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜è‡³ï¼š{output_file}\")\n",
    "except PermissionError:\n",
    "    print(f\"\\nâŒ ç„¡æ³•å¯«å…¥ '{output_file}'ï¼Œè«‹é—œé–‰æª”æ¡ˆæˆ–é¸æ“‡å…¶ä»–è·¯å¾‘ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c1863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 186\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "def get_extra_info(course_url):\n",
    "    start_time = \"\"\n",
    "    suggested_study_time = \"\"\n",
    "    study_duration = \"\"\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        start_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-za0201.cds-10.cds-11.cds-grid-item > div.cds-9.css-0.cds-11.cds-grid-item.cds-56 > div > div > div > div.cds-9.css-0.cds-11.cds-grid-item.cds-56.cds-79 > div.css-y6ppwi > div > div > div > form > button > span > div > div > span\"\n",
    "        )\n",
    "        suggested_study_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fk6qfz\"\n",
    "        )\n",
    "        study_duration_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fw9ih3\"\n",
    "        )\n",
    "        start_time = start_time_element.text.strip() if start_time_element else \"\"\n",
    "        suggested_study_time = (\n",
    "            suggested_study_time_element.text.strip()\n",
    "            if suggested_study_time_element\n",
    "            else \"\"\n",
    "        )\n",
    "        study_duration = (\n",
    "            study_duration_element.text.strip() if study_duration_element else \"\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ“·å–èª²ç¨‹é¡å¤–è³‡è¨Šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return start_time, suggested_study_time, study_duration\n",
    "\n",
    "\n",
    "def get_course_details(course_url):\n",
    "    details = {\n",
    "        \"èª²ç¨‹\": \"\",\n",
    "        \"æŠ€èƒ½\": \"\",\n",
    "        \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "        \"å¸«è³‡\": \"\",\n",
    "        \"é–‹èª²æ™‚é–“\": \"\",\n",
    "        \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "        \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        course_title = soup.find(\n",
    "            \"a\", class_=\"cds-119 cds-113 cds-115 css-17cxvu3 cds-142\", href=\"#modules\"\n",
    "        )\n",
    "        details[\"èª²ç¨‹\"] = course_title.text.strip() if course_title else \"\"\n",
    "        skills = []\n",
    "        skill_spans = soup.find_all(\"span\", {\"class\": \"css-1l1jvyr\"})\n",
    "        for span in skill_spans:\n",
    "            skill_link = span.find(\n",
    "                \"a\", {\"class\": \"cds-119 cds-113 cds-115 css-113xph7 cds-142\"}\n",
    "            )\n",
    "            if skill_link:\n",
    "                skills.append(skill_link.get_text(strip=True))\n",
    "        details[\"æŠ€èƒ½\"] = \", \".join(skills) if skills else \"\"\n",
    "        modules = []\n",
    "        for mod in soup.find_all(\"h3\", class_=\"cds-119 css-1pxm1ir cds-121\"):\n",
    "            modules.append(mod.text.strip())\n",
    "        details[\"èª²ç¨‹è³‡è¨Š\"] = \" | \".join(modules)\n",
    "        instructors = []\n",
    "        for span in soup.find_all(\"span\", class_=\"css-6ecy9b\"):\n",
    "            name = span.text.strip()\n",
    "            if (\n",
    "                name not in instructors\n",
    "                and len(name.split()) >= 2\n",
    "                and not any(\n",
    "                    keyword in name.lower()\n",
    "                    for keyword in [\n",
    "                        \"star\",\n",
    "                        \"more\",\n",
    "                        \"access\",\n",
    "                        \"certificate\",\n",
    "                        \"refund\",\n",
    "                        \"?\",\n",
    "                    ]\n",
    "                )\n",
    "            ):\n",
    "                instructors.append(name)\n",
    "        details[\"å¸«è³‡\"] = \", \".join(instructors)\n",
    "        start_time, suggested_study_time, study_duration = get_extra_info(course_url)\n",
    "        details[\"é–‹èª²æ™‚é–“\"] = start_time\n",
    "        details[\"å»ºè­°å­¸ç¿’æ™‚é–“\"] = suggested_study_time\n",
    "        details[\"å­¸ç¿’æ™‚é•·\"] = study_duration\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è©³æƒ…é é€£ç·šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return details\n",
    "\n",
    "\n",
    "page = 1\n",
    "pbar = tqdm(desc=\"æ­£åœ¨çˆ¬å–é é¢\", ncols=100)\n",
    "while True:\n",
    "    url = f\"https://www.coursera.org/courses?query=generative%20ai&page={page}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\\nâš ï¸ ç¬¬ {page} é é€£ç·šå¤±æ•—ï¼š{e}\")\n",
    "        break\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    course_cards = soup.find_all(\"div\", class_=\"cds-ProductCard-content\")\n",
    "    if not course_cards:\n",
    "        print(f\"\\nðŸ“„ ç¬¬ {page} é ç„¡èª²ç¨‹å…§å®¹ï¼Œçˆ¬èŸ²çµæŸã€‚\")\n",
    "        break\n",
    "    for card in course_cards:\n",
    "        title_elem = card.find(\"h3\", class_=\"cds-CommonCard-title css-6ecy9b\")\n",
    "        title = title_elem.text.strip() if title_elem else \"N/A\"\n",
    "        rating_elem = card.find(\"div\", class_=\"css-1whdyhf\")\n",
    "        rating = (\n",
    "            rating_elem.text.strip().replace(\"Rating, \", \"\") if rating_elem else \"N/A\"\n",
    "        )\n",
    "        review = \"N/A\"\n",
    "        review_elems = card.find_all(\"div\", class_=\"css-vac8rf\")\n",
    "        for elem in review_elems:\n",
    "            if \"reviews\" in elem.text.lower():\n",
    "                review = elem.text.strip()\n",
    "                break\n",
    "        meta_elem = card.find(\"div\", class_=\"cds-CommonCard-metadata\")\n",
    "        meta = (\n",
    "            meta_elem.find(\"p\", class_=\"css-vac8rf\").text.strip()\n",
    "            if meta_elem and meta_elem.find(\"p\", class_=\"css-vac8rf\")\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        link_elem = card.find(\"a\", class_=\"cds-CommonCard-titleLink\")\n",
    "        if link_elem and link_elem.get(\"href\"):\n",
    "            course_url = \"https://www.coursera.org\" + link_elem.get(\"href\")\n",
    "        else:\n",
    "            course_url = \"\"\n",
    "        if course_url:\n",
    "            detail_data = get_course_details(course_url)\n",
    "        else:\n",
    "            detail_data = {\n",
    "                \"èª²ç¨‹\": \"\",\n",
    "                \"æŠ€èƒ½\": \"\",\n",
    "                \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "                \"å¸«è³‡\": \"\",\n",
    "                \"é–‹èª²æ™‚é–“\": \"\",\n",
    "                \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "                \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "            }\n",
    "        row = {\n",
    "            \"èª²ç¨‹åç¨±\": title,\n",
    "            \"è©•åˆ†\": rating,\n",
    "            \"è©•è«–æ•¸\": review,\n",
    "            \"Metadata\": meta,\n",
    "            \"èª²ç¨‹ç¶²å€\": course_url,\n",
    "            \"èª²ç¨‹\": detail_data[\"èª²ç¨‹\"],\n",
    "            \"æŠ€èƒ½\": detail_data[\"æŠ€èƒ½\"],\n",
    "            \"èª²ç¨‹è³‡è¨Š\": detail_data[\"èª²ç¨‹è³‡è¨Š\"],\n",
    "            \"å¸«è³‡\": detail_data[\"å¸«è³‡\"],\n",
    "            \"é–‹èª²æ™‚é–“\": detail_data[\"é–‹èª²æ™‚é–“\"],\n",
    "            \"å»ºè­°å­¸ç¿’æ™‚é–“\": detail_data[\"å»ºè­°å­¸ç¿’æ™‚é–“\"],\n",
    "            \"å­¸ç¿’æ™‚é•·\": detail_data[\"å­¸ç¿’æ™‚é•·\"],\n",
    "        }\n",
    "        all_data.append(row)\n",
    "    page += 1\n",
    "    pbar.update(1)\n",
    "    time.sleep(3)\n",
    "pbar.close()\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "output_file = \"coursera_GenerativeAi_TS.csv\"\n",
    "try:\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… çˆ¬å–å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜è‡³ï¼š{output_file}\")\n",
    "except PermissionError:\n",
    "    print(f\"\\nâŒ ç„¡æ³•å¯«å…¥ '{output_file}'ï¼Œè«‹é—œé–‰æª”æ¡ˆæˆ–é¸æ“‡å…¶ä»–è·¯å¾‘ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebc1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "def get_extra_info(course_url):\n",
    "    start_time = \"\"\n",
    "    suggested_study_time = \"\"\n",
    "    study_duration = \"\"\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        start_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-za0201.cds-10.cds-11.cds-grid-item > div.cds-9.css-0.cds-11.cds-grid-item.cds-56 > div > div > div > div.cds-9.css-0.cds-11.cds-grid-item.cds-56.cds-79 > div.css-y6ppwi > div > div > div > form > button > span > div > div > span\"\n",
    "        )\n",
    "        suggested_study_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fk6qfz\"\n",
    "        )\n",
    "        study_duration_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fw9ih3\"\n",
    "        )\n",
    "        start_time = start_time_element.text.strip() if start_time_element else \"\"\n",
    "        suggested_study_time = (\n",
    "            suggested_study_time_element.text.strip()\n",
    "            if suggested_study_time_element\n",
    "            else \"\"\n",
    "        )\n",
    "        study_duration = (\n",
    "            study_duration_element.text.strip() if study_duration_element else \"\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ“·å–èª²ç¨‹é¡å¤–è³‡è¨Šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return start_time, suggested_study_time, study_duration\n",
    "\n",
    "\n",
    "def get_course_details(course_url):\n",
    "    details = {\n",
    "        \"èª²ç¨‹\": \"\",\n",
    "        \"æŠ€èƒ½\": \"\",\n",
    "        \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "        \"å¸«è³‡\": \"\",\n",
    "        \"é–‹èª²æ™‚é–“\": \"\",\n",
    "        \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "        \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        course_title = soup.find(\n",
    "            \"a\", class_=\"cds-119 cds-113 cds-115 css-17cxvu3 cds-142\", href=\"#modules\"\n",
    "        )\n",
    "        details[\"èª²ç¨‹\"] = course_title.text.strip() if course_title else \"\"\n",
    "        skills = []\n",
    "        skill_spans = soup.find_all(\"span\", {\"class\": \"css-1l1jvyr\"})\n",
    "        for span in skill_spans:\n",
    "            skill_link = span.find(\n",
    "                \"a\", {\"class\": \"cds-119 cds-113 cds-115 css-113xph7 cds-142\"}\n",
    "            )\n",
    "            if skill_link:\n",
    "                skills.append(skill_link.get_text(strip=True))\n",
    "        details[\"æŠ€èƒ½\"] = \", \".join(skills) if skills else \"\"\n",
    "        modules = []\n",
    "        for mod in soup.find_all(\"h3\", class_=\"cds-119 css-1pxm1ir cds-121\"):\n",
    "            modules.append(mod.text.strip())\n",
    "        details[\"èª²ç¨‹è³‡è¨Š\"] = \" | \".join(modules)\n",
    "        instructors = []\n",
    "        for span in soup.find_all(\"span\", class_=\"css-6ecy9b\"):\n",
    "            name = span.text.strip()\n",
    "            if (\n",
    "                name not in instructors\n",
    "                and len(name.split()) >= 2\n",
    "                and not any(\n",
    "                    keyword in name.lower()\n",
    "                    for keyword in [\n",
    "                        \"star\",\n",
    "                        \"more\",\n",
    "                        \"access\",\n",
    "                        \"certificate\",\n",
    "                        \"refund\",\n",
    "                        \"?\",\n",
    "                    ]\n",
    "                )\n",
    "            ):\n",
    "                instructors.append(name)\n",
    "        details[\"å¸«è³‡\"] = \", \".join(instructors)\n",
    "        start_time, suggested_study_time, study_duration = get_extra_info(course_url)\n",
    "        details[\"é–‹èª²æ™‚é–“\"] = start_time\n",
    "        details[\"å»ºè­°å­¸ç¿’æ™‚é–“\"] = suggested_study_time\n",
    "        details[\"å­¸ç¿’æ™‚é•·\"] = study_duration\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è©³æƒ…é é€£ç·šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return details\n",
    "\n",
    "\n",
    "page = 1\n",
    "pbar = tqdm(desc=\"æ­£åœ¨çˆ¬å–é é¢\", ncols=100)\n",
    "while True:\n",
    "    url = f\"https://www.coursera.org/courses?query=cybersecurity&page={page}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\\nâš ï¸ ç¬¬ {page} é é€£ç·šå¤±æ•—ï¼š{e}\")\n",
    "        break\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    course_cards = soup.find_all(\"div\", class_=\"cds-ProductCard-content\")\n",
    "    if not course_cards:\n",
    "        print(f\"\\nðŸ“„ ç¬¬ {page} é ç„¡èª²ç¨‹å…§å®¹ï¼Œçˆ¬èŸ²çµæŸã€‚\")\n",
    "        break\n",
    "    for card in course_cards:\n",
    "        title_elem = card.find(\"h3\", class_=\"cds-CommonCard-title css-6ecy9b\")\n",
    "        title = title_elem.text.strip() if title_elem else \"N/A\"\n",
    "        rating_elem = card.find(\"div\", class_=\"css-1whdyhf\")\n",
    "        rating = (\n",
    "            rating_elem.text.strip().replace(\"Rating, \", \"\") if rating_elem else \"N/A\"\n",
    "        )\n",
    "        review = \"N/A\"\n",
    "        review_elems = card.find_all(\"div\", class_=\"css-vac8rf\")\n",
    "        for elem in review_elems:\n",
    "            if \"reviews\" in elem.text.lower():\n",
    "                review = elem.text.strip()\n",
    "                break\n",
    "        meta_elem = card.find(\"div\", class_=\"cds-CommonCard-metadata\")\n",
    "        meta = (\n",
    "            meta_elem.find(\"p\", class_=\"css-vac8rf\").text.strip()\n",
    "            if meta_elem and meta_elem.find(\"p\", class_=\"css-vac8rf\")\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        link_elem = card.find(\"a\", class_=\"cds-CommonCard-titleLink\")\n",
    "        if link_elem and link_elem.get(\"href\"):\n",
    "            course_url = \"https://www.coursera.org\" + link_elem.get(\"href\")\n",
    "        else:\n",
    "            course_url = \"\"\n",
    "        if course_url:\n",
    "            detail_data = get_course_details(course_url)\n",
    "        else:\n",
    "            detail_data = {\n",
    "                \"èª²ç¨‹\": \"\",\n",
    "                \"æŠ€èƒ½\": \"\",\n",
    "                \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "                \"å¸«è³‡\": \"\",\n",
    "                \"é–‹èª²æ™‚é–“\": \"\",\n",
    "                \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "                \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "            }\n",
    "        row = {\n",
    "            \"èª²ç¨‹åç¨±\": title,\n",
    "            \"è©•åˆ†\": rating,\n",
    "            \"è©•è«–æ•¸\": review,\n",
    "            \"Metadata\": meta,\n",
    "            \"èª²ç¨‹ç¶²å€\": course_url,\n",
    "            \"èª²ç¨‹\": detail_data[\"èª²ç¨‹\"],\n",
    "            \"æŠ€èƒ½\": detail_data[\"æŠ€èƒ½\"],\n",
    "            \"èª²ç¨‹è³‡è¨Š\": detail_data[\"èª²ç¨‹è³‡è¨Š\"],\n",
    "            \"å¸«è³‡\": detail_data[\"å¸«è³‡\"],\n",
    "            \"é–‹èª²æ™‚é–“\": detail_data[\"é–‹èª²æ™‚é–“\"],\n",
    "            \"å»ºè­°å­¸ç¿’æ™‚é–“\": detail_data[\"å»ºè­°å­¸ç¿’æ™‚é–“\"],\n",
    "            \"å­¸ç¿’æ™‚é•·\": detail_data[\"å­¸ç¿’æ™‚é•·\"],\n",
    "        }\n",
    "        all_data.append(row)\n",
    "    page += 1\n",
    "    pbar.update(1)\n",
    "    time.sleep(3)\n",
    "pbar.close()\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "output_file = \"coursera_CyberSecurity_TS.csv\"\n",
    "try:\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… çˆ¬å–å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜è‡³ï¼š{output_file}\")\n",
    "except PermissionError:\n",
    "    print(f\"\\nâŒ ç„¡æ³•å¯«å…¥ '{output_file}'ï¼Œè«‹é—œé–‰æª”æ¡ˆæˆ–é¸æ“‡å…¶ä»–è·¯å¾‘ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "def get_extra_info(course_url):\n",
    "    start_time = \"\"\n",
    "    suggested_study_time = \"\"\n",
    "    study_duration = \"\"\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        start_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-za0201.cds-10.cds-11.cds-grid-item > div.cds-9.css-0.cds-11.cds-grid-item.cds-56 > div > div > div > div.cds-9.css-0.cds-11.cds-grid-item.cds-56.cds-79 > div.css-y6ppwi > div > div > div > form > button > span > div > div > span\"\n",
    "        )\n",
    "        suggested_study_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fk6qfz\"\n",
    "        )\n",
    "        study_duration_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fw9ih3\"\n",
    "        )\n",
    "        start_time = start_time_element.text.strip() if start_time_element else \"\"\n",
    "        suggested_study_time = (\n",
    "            suggested_study_time_element.text.strip()\n",
    "            if suggested_study_time_element\n",
    "            else \"\"\n",
    "        )\n",
    "        study_duration = (\n",
    "            study_duration_element.text.strip() if study_duration_element else \"\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ“·å–èª²ç¨‹é¡å¤–è³‡è¨Šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return start_time, suggested_study_time, study_duration\n",
    "\n",
    "\n",
    "def get_course_details(course_url):\n",
    "    details = {\n",
    "        \"èª²ç¨‹\": \"\",\n",
    "        \"æŠ€èƒ½\": \"\",\n",
    "        \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "        \"å¸«è³‡\": \"\",\n",
    "        \"é–‹èª²æ™‚é–“\": \"\",\n",
    "        \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "        \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        course_title = soup.find(\n",
    "            \"a\", class_=\"cds-119 cds-113 cds-115 css-17cxvu3 cds-142\", href=\"#modules\"\n",
    "        )\n",
    "        details[\"èª²ç¨‹\"] = course_title.text.strip() if course_title else \"\"\n",
    "        skills = []\n",
    "        skill_spans = soup.find_all(\"span\", {\"class\": \"css-1l1jvyr\"})\n",
    "        for span in skill_spans:\n",
    "            skill_link = span.find(\n",
    "                \"a\", {\"class\": \"cds-119 cds-113 cds-115 css-113xph7 cds-142\"}\n",
    "            )\n",
    "            if skill_link:\n",
    "                skills.append(skill_link.get_text(strip=True))\n",
    "        details[\"æŠ€èƒ½\"] = \", \".join(skills) if skills else \"\"\n",
    "        modules = []\n",
    "        for mod in soup.find_all(\"h3\", class_=\"cds-119 css-1pxm1ir cds-121\"):\n",
    "            modules.append(mod.text.strip())\n",
    "        details[\"èª²ç¨‹è³‡è¨Š\"] = \" | \".join(modules)\n",
    "        instructors = []\n",
    "        for span in soup.find_all(\"span\", class_=\"css-6ecy9b\"):\n",
    "            name = span.text.strip()\n",
    "            if (\n",
    "                name not in instructors\n",
    "                and len(name.split()) >= 2\n",
    "                and not any(\n",
    "                    keyword in name.lower()\n",
    "                    for keyword in [\n",
    "                        \"star\",\n",
    "                        \"more\",\n",
    "                        \"access\",\n",
    "                        \"certificate\",\n",
    "                        \"refund\",\n",
    "                        \"?\",\n",
    "                    ]\n",
    "                )\n",
    "            ):\n",
    "                instructors.append(name)\n",
    "        details[\"å¸«è³‡\"] = \", \".join(instructors)\n",
    "        start_time, suggested_study_time, study_duration = get_extra_info(course_url)\n",
    "        details[\"é–‹èª²æ™‚é–“\"] = start_time\n",
    "        details[\"å»ºè­°å­¸ç¿’æ™‚é–“\"] = suggested_study_time\n",
    "        details[\"å­¸ç¿’æ™‚é•·\"] = study_duration\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è©³æƒ…é é€£ç·šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return details\n",
    "\n",
    "\n",
    "page = 1\n",
    "pbar = tqdm(desc=\"æ­£åœ¨çˆ¬å–é é¢\", ncols=100)\n",
    "while True:\n",
    "    url = f\"https://www.coursera.org/courses?query=devops&page={page}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\\nâš ï¸ ç¬¬ {page} é é€£ç·šå¤±æ•—ï¼š{e}\")\n",
    "        break\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    course_cards = soup.find_all(\"div\", class_=\"cds-ProductCard-content\")\n",
    "    if not course_cards:\n",
    "        print(f\"\\nðŸ“„ ç¬¬ {page} é ç„¡èª²ç¨‹å…§å®¹ï¼Œçˆ¬èŸ²çµæŸã€‚\")\n",
    "        break\n",
    "    for card in course_cards:\n",
    "        title_elem = card.find(\"h3\", class_=\"cds-CommonCard-title css-6ecy9b\")\n",
    "        title = title_elem.text.strip() if title_elem else \"N/A\"\n",
    "        rating_elem = card.find(\"div\", class_=\"css-1whdyhf\")\n",
    "        rating = (\n",
    "            rating_elem.text.strip().replace(\"Rating, \", \"\") if rating_elem else \"N/A\"\n",
    "        )\n",
    "        review = \"N/A\"\n",
    "        review_elems = card.find_all(\"div\", class_=\"css-vac8rf\")\n",
    "        for elem in review_elems:\n",
    "            if \"reviews\" in elem.text.lower():\n",
    "                review = elem.text.strip()\n",
    "                break\n",
    "        meta_elem = card.find(\"div\", class_=\"cds-CommonCard-metadata\")\n",
    "        meta = (\n",
    "            meta_elem.find(\"p\", class_=\"css-vac8rf\").text.strip()\n",
    "            if meta_elem and meta_elem.find(\"p\", class_=\"css-vac8rf\")\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        link_elem = card.find(\"a\", class_=\"cds-CommonCard-titleLink\")\n",
    "        if link_elem and link_elem.get(\"href\"):\n",
    "            course_url = \"https://www.coursera.org\" + link_elem.get(\"href\")\n",
    "        else:\n",
    "            course_url = \"\"\n",
    "        if course_url:\n",
    "            detail_data = get_course_details(course_url)\n",
    "        else:\n",
    "            detail_data = {\n",
    "                \"èª²ç¨‹\": \"\",\n",
    "                \"æŠ€èƒ½\": \"\",\n",
    "                \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "                \"å¸«è³‡\": \"\",\n",
    "                \"é–‹èª²æ™‚é–“\": \"\",\n",
    "                \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "                \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "            }\n",
    "        row = {\n",
    "            \"èª²ç¨‹åç¨±\": title,\n",
    "            \"è©•åˆ†\": rating,\n",
    "            \"è©•è«–æ•¸\": review,\n",
    "            \"Metadata\": meta,\n",
    "            \"èª²ç¨‹ç¶²å€\": course_url,\n",
    "            \"èª²ç¨‹\": detail_data[\"èª²ç¨‹\"],\n",
    "            \"æŠ€èƒ½\": detail_data[\"æŠ€èƒ½\"],\n",
    "            \"èª²ç¨‹è³‡è¨Š\": detail_data[\"èª²ç¨‹è³‡è¨Š\"],\n",
    "            \"å¸«è³‡\": detail_data[\"å¸«è³‡\"],\n",
    "            \"é–‹èª²æ™‚é–“\": detail_data[\"é–‹èª²æ™‚é–“\"],\n",
    "            \"å»ºè­°å­¸ç¿’æ™‚é–“\": detail_data[\"å»ºè­°å­¸ç¿’æ™‚é–“\"],\n",
    "            \"å­¸ç¿’æ™‚é•·\": detail_data[\"å­¸ç¿’æ™‚é•·\"],\n",
    "        }\n",
    "        all_data.append(row)\n",
    "    page += 1\n",
    "    pbar.update(1)\n",
    "    time.sleep(3)\n",
    "pbar.close()\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "output_file = \"coursera_devops_TS.csv\"\n",
    "try:\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… çˆ¬å–å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜è‡³ï¼š{output_file}\")\n",
    "except PermissionError:\n",
    "    print(f\"\\nâŒ ç„¡æ³•å¯«å…¥ '{output_file}'ï¼Œè«‹é—œé–‰æª”æ¡ˆæˆ–é¸æ“‡å…¶ä»–è·¯å¾‘ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d59a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 72\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "def get_extra_info(course_url):\n",
    "    start_time = \"\"\n",
    "    suggested_study_time = \"\"\n",
    "    study_duration = \"\"\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        start_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-za0201.cds-10.cds-11.cds-grid-item > div.cds-9.css-0.cds-11.cds-grid-item.cds-56 > div > div > div > div.cds-9.css-0.cds-11.cds-grid-item.cds-56.cds-79 > div.css-y6ppwi > div > div > div > form > button > span > div > div > span\"\n",
    "        )\n",
    "        suggested_study_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fk6qfz\"\n",
    "        )\n",
    "        study_duration_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fw9ih3\"\n",
    "        )\n",
    "        start_time = start_time_element.text.strip() if start_time_element else \"\"\n",
    "        suggested_study_time = (\n",
    "            suggested_study_time_element.text.strip()\n",
    "            if suggested_study_time_element\n",
    "            else \"\"\n",
    "        )\n",
    "        study_duration = (\n",
    "            study_duration_element.text.strip() if study_duration_element else \"\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ“·å–èª²ç¨‹é¡å¤–è³‡è¨Šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return start_time, suggested_study_time, study_duration\n",
    "\n",
    "\n",
    "def get_course_details(course_url):\n",
    "    details = {\n",
    "        \"èª²ç¨‹\": \"\",\n",
    "        \"æŠ€èƒ½\": \"\",\n",
    "        \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "        \"å¸«è³‡\": \"\",\n",
    "        \"é–‹èª²æ™‚é–“\": \"\",\n",
    "        \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "        \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        course_title = soup.find(\n",
    "            \"a\", class_=\"cds-119 cds-113 cds-115 css-17cxvu3 cds-142\", href=\"#modules\"\n",
    "        )\n",
    "        details[\"èª²ç¨‹\"] = course_title.text.strip() if course_title else \"\"\n",
    "        skills = []\n",
    "        skill_spans = soup.find_all(\"span\", {\"class\": \"css-1l1jvyr\"})\n",
    "        for span in skill_spans:\n",
    "            skill_link = span.find(\n",
    "                \"a\", {\"class\": \"cds-119 cds-113 cds-115 css-113xph7 cds-142\"}\n",
    "            )\n",
    "            if skill_link:\n",
    "                skills.append(skill_link.get_text(strip=True))\n",
    "        details[\"æŠ€èƒ½\"] = \", \".join(skills) if skills else \"\"\n",
    "        modules = []\n",
    "        for mod in soup.find_all(\"h3\", class_=\"cds-119 css-1pxm1ir cds-121\"):\n",
    "            modules.append(mod.text.strip())\n",
    "        details[\"èª²ç¨‹è³‡è¨Š\"] = \" | \".join(modules)\n",
    "        instructors = []\n",
    "        for span in soup.find_all(\"span\", class_=\"css-6ecy9b\"):\n",
    "            name = span.text.strip()\n",
    "            if (\n",
    "                name not in instructors\n",
    "                and len(name.split()) >= 2\n",
    "                and not any(\n",
    "                    keyword in name.lower()\n",
    "                    for keyword in [\n",
    "                        \"star\",\n",
    "                        \"more\",\n",
    "                        \"access\",\n",
    "                        \"certificate\",\n",
    "                        \"refund\",\n",
    "                        \"?\",\n",
    "                    ]\n",
    "                )\n",
    "            ):\n",
    "                instructors.append(name)\n",
    "        details[\"å¸«è³‡\"] = \", \".join(instructors)\n",
    "        start_time, suggested_study_time, study_duration = get_extra_info(course_url)\n",
    "        details[\"é–‹èª²æ™‚é–“\"] = start_time\n",
    "        details[\"å»ºè­°å­¸ç¿’æ™‚é–“\"] = suggested_study_time\n",
    "        details[\"å­¸ç¿’æ™‚é•·\"] = study_duration\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è©³æƒ…é é€£ç·šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return details\n",
    "\n",
    "\n",
    "page = 1\n",
    "pbar = tqdm(desc=\"æ­£åœ¨çˆ¬å–é é¢\", ncols=100)\n",
    "while True:\n",
    "    url = f\"https://www.coursera.org/courses?query=ethical%20hacking&page={page}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\\nâš ï¸ ç¬¬ {page} é é€£ç·šå¤±æ•—ï¼š{e}\")\n",
    "        break\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    course_cards = soup.find_all(\"div\", class_=\"cds-ProductCard-content\")\n",
    "    if not course_cards:\n",
    "        print(f\"\\nðŸ“„ ç¬¬ {page} é ç„¡èª²ç¨‹å…§å®¹ï¼Œçˆ¬èŸ²çµæŸã€‚\")\n",
    "        break\n",
    "    for card in course_cards:\n",
    "        title_elem = card.find(\"h3\", class_=\"cds-CommonCard-title css-6ecy9b\")\n",
    "        title = title_elem.text.strip() if title_elem else \"N/A\"\n",
    "        rating_elem = card.find(\"div\", class_=\"css-1whdyhf\")\n",
    "        rating = (\n",
    "            rating_elem.text.strip().replace(\"Rating, \", \"\") if rating_elem else \"N/A\"\n",
    "        )\n",
    "        review = \"N/A\"\n",
    "        review_elems = card.find_all(\"div\", class_=\"css-vac8rf\")\n",
    "        for elem in review_elems:\n",
    "            if \"reviews\" in elem.text.lower():\n",
    "                review = elem.text.strip()\n",
    "                break\n",
    "        meta_elem = card.find(\"div\", class_=\"cds-CommonCard-metadata\")\n",
    "        meta = (\n",
    "            meta_elem.find(\"p\", class_=\"css-vac8rf\").text.strip()\n",
    "            if meta_elem and meta_elem.find(\"p\", class_=\"css-vac8rf\")\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        link_elem = card.find(\"a\", class_=\"cds-CommonCard-titleLink\")\n",
    "        if link_elem and link_elem.get(\"href\"):\n",
    "            course_url = \"https://www.coursera.org\" + link_elem.get(\"href\")\n",
    "        else:\n",
    "            course_url = \"\"\n",
    "        if course_url:\n",
    "            detail_data = get_course_details(course_url)\n",
    "        else:\n",
    "            detail_data = {\n",
    "                \"èª²ç¨‹\": \"\",\n",
    "                \"æŠ€èƒ½\": \"\",\n",
    "                \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "                \"å¸«è³‡\": \"\",\n",
    "                \"é–‹èª²æ™‚é–“\": \"\",\n",
    "                \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "                \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "            }\n",
    "        row = {\n",
    "            \"èª²ç¨‹åç¨±\": title,\n",
    "            \"è©•åˆ†\": rating,\n",
    "            \"è©•è«–æ•¸\": review,\n",
    "            \"Metadata\": meta,\n",
    "            \"èª²ç¨‹ç¶²å€\": course_url,\n",
    "            \"èª²ç¨‹\": detail_data[\"èª²ç¨‹\"],\n",
    "            \"æŠ€èƒ½\": detail_data[\"æŠ€èƒ½\"],\n",
    "            \"èª²ç¨‹è³‡è¨Š\": detail_data[\"èª²ç¨‹è³‡è¨Š\"],\n",
    "            \"å¸«è³‡\": detail_data[\"å¸«è³‡\"],\n",
    "            \"é–‹èª²æ™‚é–“\": detail_data[\"é–‹èª²æ™‚é–“\"],\n",
    "            \"å»ºè­°å­¸ç¿’æ™‚é–“\": detail_data[\"å»ºè­°å­¸ç¿’æ™‚é–“\"],\n",
    "            \"å­¸ç¿’æ™‚é•·\": detail_data[\"å­¸ç¿’æ™‚é•·\"],\n",
    "        }\n",
    "        all_data.append(row)\n",
    "    page += 1\n",
    "    pbar.update(1)\n",
    "    time.sleep(3)\n",
    "pbar.close()\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "output_file = \"coursera_EthicalHacking_TS.csv\"\n",
    "try:\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… çˆ¬å–å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜è‡³ï¼š{output_file}\")\n",
    "except PermissionError:\n",
    "    print(f\"\\nâŒ ç„¡æ³•å¯«å…¥ '{output_file}'ï¼Œè«‹é—œé–‰æª”æ¡ˆæˆ–é¸æ“‡å…¶ä»–è·¯å¾‘ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbf4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 55\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "def get_extra_info(course_url):\n",
    "    start_time = \"\"\n",
    "    suggested_study_time = \"\"\n",
    "    study_duration = \"\"\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        start_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-za0201.cds-10.cds-11.cds-grid-item > div.cds-9.css-0.cds-11.cds-grid-item.cds-56 > div > div > div > div.cds-9.css-0.cds-11.cds-grid-item.cds-56.cds-79 > div.css-y6ppwi > div > div > div > form > button > span > div > div > span\"\n",
    "        )\n",
    "        suggested_study_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fk6qfz\"\n",
    "        )\n",
    "        study_duration_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fw9ih3\"\n",
    "        )\n",
    "        start_time = start_time_element.text.strip() if start_time_element else \"\"\n",
    "        suggested_study_time = (\n",
    "            suggested_study_time_element.text.strip()\n",
    "            if suggested_study_time_element\n",
    "            else \"\"\n",
    "        )\n",
    "        study_duration = (\n",
    "            study_duration_element.text.strip() if study_duration_element else \"\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ“·å–èª²ç¨‹é¡å¤–è³‡è¨Šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return start_time, suggested_study_time, study_duration\n",
    "\n",
    "\n",
    "def get_course_details(course_url):\n",
    "    details = {\n",
    "        \"èª²ç¨‹\": \"\",\n",
    "        \"æŠ€èƒ½\": \"\",\n",
    "        \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "        \"å¸«è³‡\": \"\",\n",
    "        \"é–‹èª²æ™‚é–“\": \"\",\n",
    "        \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "        \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        course_title = soup.find(\n",
    "            \"a\", class_=\"cds-119 cds-113 cds-115 css-17cxvu3 cds-142\", href=\"#modules\"\n",
    "        )\n",
    "        details[\"èª²ç¨‹\"] = course_title.text.strip() if course_title else \"\"\n",
    "        skills = []\n",
    "        skill_spans = soup.find_all(\"span\", {\"class\": \"css-1l1jvyr\"})\n",
    "        for span in skill_spans:\n",
    "            skill_link = span.find(\n",
    "                \"a\", {\"class\": \"cds-119 cds-113 cds-115 css-113xph7 cds-142\"}\n",
    "            )\n",
    "            if skill_link:\n",
    "                skills.append(skill_link.get_text(strip=True))\n",
    "        details[\"æŠ€èƒ½\"] = \", \".join(skills) if skills else \"\"\n",
    "        modules = []\n",
    "        for mod in soup.find_all(\"h3\", class_=\"cds-119 css-1pxm1ir cds-121\"):\n",
    "            modules.append(mod.text.strip())\n",
    "        details[\"èª²ç¨‹è³‡è¨Š\"] = \" | \".join(modules)\n",
    "        instructors = []\n",
    "        for span in soup.find_all(\"span\", class_=\"css-6ecy9b\"):\n",
    "            name = span.text.strip()\n",
    "            if (\n",
    "                name not in instructors\n",
    "                and len(name.split()) >= 2\n",
    "                and not any(\n",
    "                    keyword in name.lower()\n",
    "                    for keyword in [\n",
    "                        \"star\",\n",
    "                        \"more\",\n",
    "                        \"access\",\n",
    "                        \"certificate\",\n",
    "                        \"refund\",\n",
    "                        \"?\",\n",
    "                    ]\n",
    "                )\n",
    "            ):\n",
    "                instructors.append(name)\n",
    "        details[\"å¸«è³‡\"] = \", \".join(instructors)\n",
    "        start_time, suggested_study_time, study_duration = get_extra_info(course_url)\n",
    "        details[\"é–‹èª²æ™‚é–“\"] = start_time\n",
    "        details[\"å»ºè­°å­¸ç¿’æ™‚é–“\"] = suggested_study_time\n",
    "        details[\"å­¸ç¿’æ™‚é•·\"] = study_duration\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è©³æƒ…é é€£ç·šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return details\n",
    "\n",
    "\n",
    "page = 1\n",
    "pbar = tqdm(desc=\"æ­£åœ¨çˆ¬å–é é¢\", ncols=100)\n",
    "while True:\n",
    "    url = f\"https://www.coursera.org/courses?query=java&page={page}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\\nâš ï¸ ç¬¬ {page} é é€£ç·šå¤±æ•—ï¼š{e}\")\n",
    "        break\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    course_cards = soup.find_all(\"div\", class_=\"cds-ProductCard-content\")\n",
    "    if not course_cards:\n",
    "        print(f\"\\nðŸ“„ ç¬¬ {page} é ç„¡èª²ç¨‹å…§å®¹ï¼Œçˆ¬èŸ²çµæŸã€‚\")\n",
    "        break\n",
    "    for card in course_cards:\n",
    "        title_elem = card.find(\"h3\", class_=\"cds-CommonCard-title css-6ecy9b\")\n",
    "        title = title_elem.text.strip() if title_elem else \"N/A\"\n",
    "        rating_elem = card.find(\"div\", class_=\"css-1whdyhf\")\n",
    "        rating = (\n",
    "            rating_elem.text.strip().replace(\"Rating, \", \"\") if rating_elem else \"N/A\"\n",
    "        )\n",
    "        review = \"N/A\"\n",
    "        review_elems = card.find_all(\"div\", class_=\"css-vac8rf\")\n",
    "        for elem in review_elems:\n",
    "            if \"reviews\" in elem.text.lower():\n",
    "                review = elem.text.strip()\n",
    "                break\n",
    "        meta_elem = card.find(\"div\", class_=\"cds-CommonCard-metadata\")\n",
    "        meta = (\n",
    "            meta_elem.find(\"p\", class_=\"css-vac8rf\").text.strip()\n",
    "            if meta_elem and meta_elem.find(\"p\", class_=\"css-vac8rf\")\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        link_elem = card.find(\"a\", class_=\"cds-CommonCard-titleLink\")\n",
    "        if link_elem and link_elem.get(\"href\"):\n",
    "            course_url = \"https://www.coursera.org\" + link_elem.get(\"href\")\n",
    "        else:\n",
    "            course_url = \"\"\n",
    "        if course_url:\n",
    "            detail_data = get_course_details(course_url)\n",
    "        else:\n",
    "            detail_data = {\n",
    "                \"èª²ç¨‹\": \"\",\n",
    "                \"æŠ€èƒ½\": \"\",\n",
    "                \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "                \"å¸«è³‡\": \"\",\n",
    "                \"é–‹èª²æ™‚é–“\": \"\",\n",
    "                \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "                \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "            }\n",
    "        row = {\n",
    "            \"èª²ç¨‹åç¨±\": title,\n",
    "            \"è©•åˆ†\": rating,\n",
    "            \"è©•è«–æ•¸\": review,\n",
    "            \"Metadata\": meta,\n",
    "            \"èª²ç¨‹ç¶²å€\": course_url,\n",
    "            \"èª²ç¨‹\": detail_data[\"èª²ç¨‹\"],\n",
    "            \"æŠ€èƒ½\": detail_data[\"æŠ€èƒ½\"],\n",
    "            \"èª²ç¨‹è³‡è¨Š\": detail_data[\"èª²ç¨‹è³‡è¨Š\"],\n",
    "            \"å¸«è³‡\": detail_data[\"å¸«è³‡\"],\n",
    "            \"é–‹èª²æ™‚é–“\": detail_data[\"é–‹èª²æ™‚é–“\"],\n",
    "            \"å»ºè­°å­¸ç¿’æ™‚é–“\": detail_data[\"å»ºè­°å­¸ç¿’æ™‚é–“\"],\n",
    "            \"å­¸ç¿’æ™‚é•·\": detail_data[\"å­¸ç¿’æ™‚é•·\"],\n",
    "        }\n",
    "        all_data.append(row)\n",
    "    page += 1\n",
    "    pbar.update(1)\n",
    "    time.sleep(3)\n",
    "pbar.close()\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "output_file = \"coursera_java_TS.csv\"\n",
    "try:\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… çˆ¬å–å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜è‡³ï¼š{output_file}\")\n",
    "except PermissionError:\n",
    "    print(f\"\\nâŒ ç„¡æ³•å¯«å…¥ '{output_file}'ï¼Œè«‹é—œé–‰æª”æ¡ˆæˆ–é¸æ“‡å…¶ä»–è·¯å¾‘ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb88aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 649\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "def get_extra_info(course_url):\n",
    "    start_time = \"\"\n",
    "    suggested_study_time = \"\"\n",
    "    study_duration = \"\"\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        start_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-za0201.cds-10.cds-11.cds-grid-item > div.cds-9.css-0.cds-11.cds-grid-item.cds-56 > div > div > div > div.cds-9.css-0.cds-11.cds-grid-item.cds-56.cds-79 > div.css-y6ppwi > div > div > div > form > button > span > div > div > span\"\n",
    "        )\n",
    "        suggested_study_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fk6qfz\"\n",
    "        )\n",
    "        study_duration_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fw9ih3\"\n",
    "        )\n",
    "        start_time = start_time_element.text.strip() if start_time_element else \"\"\n",
    "        suggested_study_time = (\n",
    "            suggested_study_time_element.text.strip()\n",
    "            if suggested_study_time_element\n",
    "            else \"\"\n",
    "        )\n",
    "        study_duration = (\n",
    "            study_duration_element.text.strip() if study_duration_element else \"\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ“·å–èª²ç¨‹é¡å¤–è³‡è¨Šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return start_time, suggested_study_time, study_duration\n",
    "\n",
    "\n",
    "def get_course_details(course_url):\n",
    "    details = {\n",
    "        \"èª²ç¨‹\": \"\",\n",
    "        \"æŠ€èƒ½\": \"\",\n",
    "        \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "        \"å¸«è³‡\": \"\",\n",
    "        \"é–‹èª²æ™‚é–“\": \"\",\n",
    "        \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "        \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        course_title = soup.find(\n",
    "            \"a\", class_=\"cds-119 cds-113 cds-115 css-17cxvu3 cds-142\", href=\"#modules\"\n",
    "        )\n",
    "        details[\"èª²ç¨‹\"] = course_title.text.strip() if course_title else \"\"\n",
    "        skills = []\n",
    "        skill_spans = soup.find_all(\"span\", {\"class\": \"css-1l1jvyr\"})\n",
    "        for span in skill_spans:\n",
    "            skill_link = span.find(\n",
    "                \"a\", {\"class\": \"cds-119 cds-113 cds-115 css-113xph7 cds-142\"}\n",
    "            )\n",
    "            if skill_link:\n",
    "                skills.append(skill_link.get_text(strip=True))\n",
    "        details[\"æŠ€èƒ½\"] = \", \".join(skills) if skills else \"\"\n",
    "        modules = []\n",
    "        for mod in soup.find_all(\"h3\", class_=\"cds-119 css-1pxm1ir cds-121\"):\n",
    "            modules.append(mod.text.strip())\n",
    "        details[\"èª²ç¨‹è³‡è¨Š\"] = \" | \".join(modules)\n",
    "        instructors = []\n",
    "        for span in soup.find_all(\"span\", class_=\"css-6ecy9b\"):\n",
    "            name = span.text.strip()\n",
    "            if (\n",
    "                name not in instructors\n",
    "                and len(name.split()) >= 2\n",
    "                and not any(\n",
    "                    keyword in name.lower()\n",
    "                    for keyword in [\n",
    "                        \"star\",\n",
    "                        \"more\",\n",
    "                        \"access\",\n",
    "                        \"certificate\",\n",
    "                        \"refund\",\n",
    "                        \"?\",\n",
    "                    ]\n",
    "                )\n",
    "            ):\n",
    "                instructors.append(name)\n",
    "        details[\"å¸«è³‡\"] = \", \".join(instructors)\n",
    "        start_time, suggested_study_time, study_duration = get_extra_info(course_url)\n",
    "        details[\"é–‹èª²æ™‚é–“\"] = start_time\n",
    "        details[\"å»ºè­°å­¸ç¿’æ™‚é–“\"] = suggested_study_time\n",
    "        details[\"å­¸ç¿’æ™‚é•·\"] = study_duration\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è©³æƒ…é é€£ç·šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return details\n",
    "\n",
    "\n",
    "page = 1\n",
    "pbar = tqdm(desc=\"æ­£åœ¨çˆ¬å–é é¢\", ncols=100)\n",
    "while True:\n",
    "    url = f\"https://www.coursera.org/courses?query=web%20development&page={page}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\\nâš ï¸ ç¬¬ {page} é é€£ç·šå¤±æ•—ï¼š{e}\")\n",
    "        break\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    course_cards = soup.find_all(\"div\", class_=\"cds-ProductCard-content\")\n",
    "    if not course_cards:\n",
    "        print(f\"\\nðŸ“„ ç¬¬ {page} é ç„¡èª²ç¨‹å…§å®¹ï¼Œçˆ¬èŸ²çµæŸã€‚\")\n",
    "        break\n",
    "    for card in course_cards:\n",
    "        title_elem = card.find(\"h3\", class_=\"cds-CommonCard-title css-6ecy9b\")\n",
    "        title = title_elem.text.strip() if title_elem else \"N/A\"\n",
    "        rating_elem = card.find(\"div\", class_=\"css-1whdyhf\")\n",
    "        rating = (\n",
    "            rating_elem.text.strip().replace(\"Rating, \", \"\") if rating_elem else \"N/A\"\n",
    "        )\n",
    "        review = \"N/A\"\n",
    "        review_elems = card.find_all(\"div\", class_=\"css-vac8rf\")\n",
    "        for elem in review_elems:\n",
    "            if \"reviews\" in elem.text.lower():\n",
    "                review = elem.text.strip()\n",
    "                break\n",
    "        meta_elem = card.find(\"div\", class_=\"cds-CommonCard-metadata\")\n",
    "        meta = (\n",
    "            meta_elem.find(\"p\", class_=\"css-vac8rf\").text.strip()\n",
    "            if meta_elem and meta_elem.find(\"p\", class_=\"css-vac8rf\")\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        link_elem = card.find(\"a\", class_=\"cds-CommonCard-titleLink\")\n",
    "        if link_elem and link_elem.get(\"href\"):\n",
    "            course_url = \"https://www.coursera.org\" + link_elem.get(\"href\")\n",
    "        else:\n",
    "            course_url = \"\"\n",
    "        if course_url:\n",
    "            detail_data = get_course_details(course_url)\n",
    "        else:\n",
    "            detail_data = {\n",
    "                \"èª²ç¨‹\": \"\",\n",
    "                \"æŠ€èƒ½\": \"\",\n",
    "                \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "                \"å¸«è³‡\": \"\",\n",
    "                \"é–‹èª²æ™‚é–“\": \"\",\n",
    "                \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "                \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "            }\n",
    "        row = {\n",
    "            \"èª²ç¨‹åç¨±\": title,\n",
    "            \"è©•åˆ†\": rating,\n",
    "            \"è©•è«–æ•¸\": review,\n",
    "            \"Metadata\": meta,\n",
    "            \"èª²ç¨‹ç¶²å€\": course_url,\n",
    "            \"èª²ç¨‹\": detail_data[\"èª²ç¨‹\"],\n",
    "            \"æŠ€èƒ½\": detail_data[\"æŠ€èƒ½\"],\n",
    "            \"èª²ç¨‹è³‡è¨Š\": detail_data[\"èª²ç¨‹è³‡è¨Š\"],\n",
    "            \"å¸«è³‡\": detail_data[\"å¸«è³‡\"],\n",
    "            \"é–‹èª²æ™‚é–“\": detail_data[\"é–‹èª²æ™‚é–“\"],\n",
    "            \"å»ºè­°å­¸ç¿’æ™‚é–“\": detail_data[\"å»ºè­°å­¸ç¿’æ™‚é–“\"],\n",
    "            \"å­¸ç¿’æ™‚é•·\": detail_data[\"å­¸ç¿’æ™‚é•·\"],\n",
    "        }\n",
    "        all_data.append(row)\n",
    "    page += 1\n",
    "    pbar.update(1)\n",
    "    time.sleep(3)\n",
    "pbar.close()\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "output_file = \"coursera_WebDevelopment_TS.csv\"\n",
    "try:\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… çˆ¬å–å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜è‡³ï¼š{output_file}\")\n",
    "except PermissionError:\n",
    "    print(f\"\\nâŒ ç„¡æ³•å¯«å…¥ '{output_file}'ï¼Œè«‹é—œé–‰æª”æ¡ˆæˆ–é¸æ“‡å…¶ä»–è·¯å¾‘ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ee5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 280\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "def get_extra_info(course_url):\n",
    "    start_time = \"\"\n",
    "    suggested_study_time = \"\"\n",
    "    study_duration = \"\"\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        start_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-za0201.cds-10.cds-11.cds-grid-item > div.cds-9.css-0.cds-11.cds-grid-item.cds-56 > div > div > div > div.cds-9.css-0.cds-11.cds-grid-item.cds-56.cds-79 > div.css-y6ppwi > div > div > div > form > button > span > div > div > span\"\n",
    "        )\n",
    "        suggested_study_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fk6qfz\"\n",
    "        )\n",
    "        study_duration_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fw9ih3\"\n",
    "        )\n",
    "        start_time = start_time_element.text.strip() if start_time_element else \"\"\n",
    "        suggested_study_time = (\n",
    "            suggested_study_time_element.text.strip()\n",
    "            if suggested_study_time_element\n",
    "            else \"\"\n",
    "        )\n",
    "        study_duration = (\n",
    "            study_duration_element.text.strip() if study_duration_element else \"\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ“·å–èª²ç¨‹é¡å¤–è³‡è¨Šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return start_time, suggested_study_time, study_duration\n",
    "\n",
    "\n",
    "def get_course_details(course_url):\n",
    "    details = {\n",
    "        \"èª²ç¨‹\": \"\",\n",
    "        \"æŠ€èƒ½\": \"\",\n",
    "        \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "        \"å¸«è³‡\": \"\",\n",
    "        \"é–‹èª²æ™‚é–“\": \"\",\n",
    "        \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "        \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        course_title = soup.find(\n",
    "            \"a\", class_=\"cds-119 cds-113 cds-115 css-17cxvu3 cds-142\", href=\"#modules\"\n",
    "        )\n",
    "        details[\"èª²ç¨‹\"] = course_title.text.strip() if course_title else \"\"\n",
    "        skills = []\n",
    "        skill_spans = soup.find_all(\"span\", {\"class\": \"css-1l1jvyr\"})\n",
    "        for span in skill_spans:\n",
    "            skill_link = span.find(\n",
    "                \"a\", {\"class\": \"cds-119 cds-113 cds-115 css-113xph7 cds-142\"}\n",
    "            )\n",
    "            if skill_link:\n",
    "                skills.append(skill_link.get_text(strip=True))\n",
    "        details[\"æŠ€èƒ½\"] = \", \".join(skills) if skills else \"\"\n",
    "        modules = []\n",
    "        for mod in soup.find_all(\"h3\", class_=\"cds-119 css-1pxm1ir cds-121\"):\n",
    "            modules.append(mod.text.strip())\n",
    "        details[\"èª²ç¨‹è³‡è¨Š\"] = \" | \".join(modules)\n",
    "        instructors = []\n",
    "        for span in soup.find_all(\"span\", class_=\"css-6ecy9b\"):\n",
    "            name = span.text.strip()\n",
    "            if (\n",
    "                name not in instructors\n",
    "                and len(name.split()) >= 2\n",
    "                and not any(\n",
    "                    keyword in name.lower()\n",
    "                    for keyword in [\n",
    "                        \"star\",\n",
    "                        \"more\",\n",
    "                        \"access\",\n",
    "                        \"certificate\",\n",
    "                        \"refund\",\n",
    "                        \"?\",\n",
    "                    ]\n",
    "                )\n",
    "            ):\n",
    "                instructors.append(name)\n",
    "        details[\"å¸«è³‡\"] = \", \".join(instructors)\n",
    "        start_time, suggested_study_time, study_duration = get_extra_info(course_url)\n",
    "        details[\"é–‹èª²æ™‚é–“\"] = start_time\n",
    "        details[\"å»ºè­°å­¸ç¿’æ™‚é–“\"] = suggested_study_time\n",
    "        details[\"å­¸ç¿’æ™‚é•·\"] = study_duration\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è©³æƒ…é é€£ç·šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return details\n",
    "\n",
    "\n",
    "page = 1\n",
    "pbar = tqdm(desc=\"æ­£åœ¨çˆ¬å–é é¢\", ncols=100)\n",
    "while True:\n",
    "    url = f\"https://www.coursera.org/courses?query=computer%20science&page={page}&topic=Computer%20Science\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\\nâš ï¸ ç¬¬ {page} é é€£ç·šå¤±æ•—ï¼š{e}\")\n",
    "        break\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    course_cards = soup.find_all(\"div\", class_=\"cds-ProductCard-content\")\n",
    "    if not course_cards:\n",
    "        print(f\"\\nðŸ“„ ç¬¬ {page} é ç„¡èª²ç¨‹å…§å®¹ï¼Œçˆ¬èŸ²çµæŸã€‚\")\n",
    "        break\n",
    "    for card in course_cards:\n",
    "        title_elem = card.find(\"h3\", class_=\"cds-CommonCard-title css-6ecy9b\")\n",
    "        title = title_elem.text.strip() if title_elem else \"N/A\"\n",
    "        rating_elem = card.find(\"div\", class_=\"css-1whdyhf\")\n",
    "        rating = (\n",
    "            rating_elem.text.strip().replace(\"Rating, \", \"\") if rating_elem else \"N/A\"\n",
    "        )\n",
    "        review = \"N/A\"\n",
    "        review_elems = card.find_all(\"div\", class_=\"css-vac8rf\")\n",
    "        for elem in review_elems:\n",
    "            if \"reviews\" in elem.text.lower():\n",
    "                review = elem.text.strip()\n",
    "                break\n",
    "        meta_elem = card.find(\"div\", class_=\"cds-CommonCard-metadata\")\n",
    "        meta = (\n",
    "            meta_elem.find(\"p\", class_=\"css-vac8rf\").text.strip()\n",
    "            if meta_elem and meta_elem.find(\"p\", class_=\"css-vac8rf\")\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        link_elem = card.find(\"a\", class_=\"cds-CommonCard-titleLink\")\n",
    "        if link_elem and link_elem.get(\"href\"):\n",
    "            course_url = \"https://www.coursera.org\" + link_elem.get(\"href\")\n",
    "        else:\n",
    "            course_url = \"\"\n",
    "        if course_url:\n",
    "            detail_data = get_course_details(course_url)\n",
    "        else:\n",
    "            detail_data = {\n",
    "                \"èª²ç¨‹\": \"\",\n",
    "                \"æŠ€èƒ½\": \"\",\n",
    "                \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "                \"å¸«è³‡\": \"\",\n",
    "                \"é–‹èª²æ™‚é–“\": \"\",\n",
    "                \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "                \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "            }\n",
    "        row = {\n",
    "            \"èª²ç¨‹åç¨±\": title,\n",
    "            \"è©•åˆ†\": rating,\n",
    "            \"è©•è«–æ•¸\": review,\n",
    "            \"Metadata\": meta,\n",
    "            \"èª²ç¨‹ç¶²å€\": course_url,\n",
    "            \"èª²ç¨‹\": detail_data[\"èª²ç¨‹\"],\n",
    "            \"æŠ€èƒ½\": detail_data[\"æŠ€èƒ½\"],\n",
    "            \"èª²ç¨‹è³‡è¨Š\": detail_data[\"èª²ç¨‹è³‡è¨Š\"],\n",
    "            \"å¸«è³‡\": detail_data[\"å¸«è³‡\"],\n",
    "            \"é–‹èª²æ™‚é–“\": detail_data[\"é–‹èª²æ™‚é–“\"],\n",
    "            \"å»ºè­°å­¸ç¿’æ™‚é–“\": detail_data[\"å»ºè­°å­¸ç¿’æ™‚é–“\"],\n",
    "            \"å­¸ç¿’æ™‚é•·\": detail_data[\"å­¸ç¿’æ™‚é•·\"],\n",
    "        }\n",
    "        all_data.append(row)\n",
    "    page += 1\n",
    "    pbar.update(1)\n",
    "    time.sleep(3)\n",
    "pbar.close()\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "output_file = \"coursera_ComputerScience_TS.csv\"\n",
    "try:\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… çˆ¬å–å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜è‡³ï¼š{output_file}\")\n",
    "except PermissionError:\n",
    "    print(f\"\\nâŒ ç„¡æ³•å¯«å…¥ '{output_file}'ï¼Œè«‹é—œé–‰æª”æ¡ˆæˆ–é¸æ“‡å…¶ä»–è·¯å¾‘ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747a6242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 102\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "def get_extra_info(course_url):\n",
    "    start_time = \"\"\n",
    "    suggested_study_time = \"\"\n",
    "    study_duration = \"\"\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        start_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-za0201.cds-10.cds-11.cds-grid-item > div.cds-9.css-0.cds-11.cds-grid-item.cds-56 > div > div > div > div.cds-9.css-0.cds-11.cds-grid-item.cds-56.cds-79 > div.css-y6ppwi > div > div > div > form > button > span > div > div > span\"\n",
    "        )\n",
    "        suggested_study_time_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fk6qfz\"\n",
    "        )\n",
    "        study_duration_element = soup.select_one(\n",
    "            \"#rendered-content > div > main > section.css-oe48t8 > div > div > div.cds-9.css-xtzux6.cds-11.cds-grid-item > div > div.css-2qp4i2.cds-168 > div:nth-child(4) > div > div > div.css-fw9ih3\"\n",
    "        )\n",
    "        start_time = start_time_element.text.strip() if start_time_element else \"\"\n",
    "        suggested_study_time = (\n",
    "            suggested_study_time_element.text.strip()\n",
    "            if suggested_study_time_element\n",
    "            else \"\"\n",
    "        )\n",
    "        study_duration = (\n",
    "            study_duration_element.text.strip() if study_duration_element else \"\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ“·å–èª²ç¨‹é¡å¤–è³‡è¨Šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return start_time, suggested_study_time, study_duration\n",
    "\n",
    "\n",
    "def get_course_details(course_url):\n",
    "    details = {\n",
    "        \"èª²ç¨‹\": \"\",\n",
    "        \"æŠ€èƒ½\": \"\",\n",
    "        \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "        \"å¸«è³‡\": \"\",\n",
    "        \"é–‹èª²æ™‚é–“\": \"\",\n",
    "        \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "        \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(course_url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        course_title = soup.find(\n",
    "            \"a\", class_=\"cds-119 cds-113 cds-115 css-17cxvu3 cds-142\", href=\"#modules\"\n",
    "        )\n",
    "        details[\"èª²ç¨‹\"] = course_title.text.strip() if course_title else \"\"\n",
    "        skills = []\n",
    "        skill_spans = soup.find_all(\"span\", {\"class\": \"css-1l1jvyr\"})\n",
    "        for span in skill_spans:\n",
    "            skill_link = span.find(\n",
    "                \"a\", {\"class\": \"cds-119 cds-113 cds-115 css-113xph7 cds-142\"}\n",
    "            )\n",
    "            if skill_link:\n",
    "                skills.append(skill_link.get_text(strip=True))\n",
    "        details[\"æŠ€èƒ½\"] = \", \".join(skills) if skills else \"\"\n",
    "        modules = []\n",
    "        for mod in soup.find_all(\"h3\", class_=\"cds-119 css-1pxm1ir cds-121\"):\n",
    "            modules.append(mod.text.strip())\n",
    "        details[\"èª²ç¨‹è³‡è¨Š\"] = \" | \".join(modules)\n",
    "        instructors = []\n",
    "        for span in soup.find_all(\"span\", class_=\"css-6ecy9b\"):\n",
    "            name = span.text.strip()\n",
    "            if (\n",
    "                name not in instructors\n",
    "                and len(name.split()) >= 2\n",
    "                and not any(\n",
    "                    keyword in name.lower()\n",
    "                    for keyword in [\n",
    "                        \"star\",\n",
    "                        \"more\",\n",
    "                        \"access\",\n",
    "                        \"certificate\",\n",
    "                        \"refund\",\n",
    "                        \"?\",\n",
    "                    ]\n",
    "                )\n",
    "            ):\n",
    "                instructors.append(name)\n",
    "        details[\"å¸«è³‡\"] = \", \".join(instructors)\n",
    "        start_time, suggested_study_time, study_duration = get_extra_info(course_url)\n",
    "        details[\"é–‹èª²æ™‚é–“\"] = start_time\n",
    "        details[\"å»ºè­°å­¸ç¿’æ™‚é–“\"] = suggested_study_time\n",
    "        details[\"å­¸ç¿’æ™‚é•·\"] = study_duration\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è©³æƒ…é é€£ç·šå¤±æ•—ï¼š{course_url}ï¼ŒéŒ¯èª¤ï¼š{e}\")\n",
    "    return details\n",
    "\n",
    "\n",
    "page = 1\n",
    "pbar = tqdm(desc=\"æ­£åœ¨çˆ¬å–é é¢\", ncols=100)\n",
    "while True:\n",
    "    url = f\"https://www.coursera.org/courses?query=python&page={page}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\\nâš ï¸ ç¬¬ {page} é é€£ç·šå¤±æ•—ï¼š{e}\")\n",
    "        break\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    course_cards = soup.find_all(\"div\", class_=\"cds-ProductCard-content\")\n",
    "    if not course_cards:\n",
    "        print(f\"\\nðŸ“„ ç¬¬ {page} é ç„¡èª²ç¨‹å…§å®¹ï¼Œçˆ¬èŸ²çµæŸã€‚\")\n",
    "        break\n",
    "    for card in course_cards:\n",
    "        title_elem = card.find(\"h3\", class_=\"cds-CommonCard-title css-6ecy9b\")\n",
    "        title = title_elem.text.strip() if title_elem else \"N/A\"\n",
    "        rating_elem = card.find(\"div\", class_=\"css-1whdyhf\")\n",
    "        rating = (\n",
    "            rating_elem.text.strip().replace(\"Rating, \", \"\") if rating_elem else \"N/A\"\n",
    "        )\n",
    "        review = \"N/A\"\n",
    "        review_elems = card.find_all(\"div\", class_=\"css-vac8rf\")\n",
    "        for elem in review_elems:\n",
    "            if \"reviews\" in elem.text.lower():\n",
    "                review = elem.text.strip()\n",
    "                break\n",
    "        meta_elem = card.find(\"div\", class_=\"cds-CommonCard-metadata\")\n",
    "        meta = (\n",
    "            meta_elem.find(\"p\", class_=\"css-vac8rf\").text.strip()\n",
    "            if meta_elem and meta_elem.find(\"p\", class_=\"css-vac8rf\")\n",
    "            else \"N/A\"\n",
    "        )\n",
    "        link_elem = card.find(\"a\", class_=\"cds-CommonCard-titleLink\")\n",
    "        if link_elem and link_elem.get(\"href\"):\n",
    "            course_url = \"https://www.coursera.org\" + link_elem.get(\"href\")\n",
    "        else:\n",
    "            course_url = \"\"\n",
    "        if course_url:\n",
    "            detail_data = get_course_details(course_url)\n",
    "        else:\n",
    "            detail_data = {\n",
    "                \"èª²ç¨‹\": \"\",\n",
    "                \"æŠ€èƒ½\": \"\",\n",
    "                \"èª²ç¨‹è³‡è¨Š\": \"\",\n",
    "                \"å¸«è³‡\": \"\",\n",
    "                \"é–‹èª²æ™‚é–“\": \"\",\n",
    "                \"å»ºè­°å­¸ç¿’æ™‚é–“\": \"\",\n",
    "                \"å­¸ç¿’æ™‚é•·\": \"\",\n",
    "            }\n",
    "        row = {\n",
    "            \"èª²ç¨‹åç¨±\": title,\n",
    "            \"è©•åˆ†\": rating,\n",
    "            \"è©•è«–æ•¸\": review,\n",
    "            \"Metadata\": meta,\n",
    "            \"èª²ç¨‹ç¶²å€\": course_url,\n",
    "            \"èª²ç¨‹\": detail_data[\"èª²ç¨‹\"],\n",
    "            \"æŠ€èƒ½\": detail_data[\"æŠ€èƒ½\"],\n",
    "            \"èª²ç¨‹è³‡è¨Š\": detail_data[\"èª²ç¨‹è³‡è¨Š\"],\n",
    "            \"å¸«è³‡\": detail_data[\"å¸«è³‡\"],\n",
    "            \"é–‹èª²æ™‚é–“\": detail_data[\"é–‹èª²æ™‚é–“\"],\n",
    "            \"å»ºè­°å­¸ç¿’æ™‚é–“\": detail_data[\"å»ºè­°å­¸ç¿’æ™‚é–“\"],\n",
    "            \"å­¸ç¿’æ™‚é•·\": detail_data[\"å­¸ç¿’æ™‚é•·\"],\n",
    "        }\n",
    "        all_data.append(row)\n",
    "    page += 1\n",
    "    pbar.update(1)\n",
    "    time.sleep(3)\n",
    "pbar.close()\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "output_file = \"coursera_python_TS.csv\"\n",
    "try:\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… çˆ¬å–å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜è‡³ï¼š{output_file}\")\n",
    "except PermissionError:\n",
    "    print(f\"\\nâŒ ç„¡æ³•å¯«å…¥ '{output_file}'ï¼Œè«‹é—œé–‰æª”æ¡ˆæˆ–é¸æ“‡å…¶ä»–è·¯å¾‘ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
